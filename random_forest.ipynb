{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIN-yfZJlhc_"
      },
      "source": [
        "# **Random Forest (Bosques Aleatorios)**\n",
        "\n",
        "### Aprendizaje Supervisado / Clasificación\n",
        "\n",
        "## Bagging\n",
        "_Minería de datos_\n",
        "\n",
        "---\n",
        "\n",
        "Para poder comprender de qué trata el modelo de machine learning Random Forest es preciso antes hablar sobre los árboles de decisión. A contiuación se describe a grandes rasgos este concepto.\n",
        "\n",
        "\n",
        "# **Arboles de decisión**\n",
        "\n",
        "## **Introducción**\n",
        "\n",
        "Los árboles de decisión son un popular método de aprendizaje supervisado siendo capaz de realizar tareas de regresión y clasificación, uniéndose así al grupo de algoritmos que hemos revisado en clases anteriores. Los árboles de decisión son fáciles de utilizar y entender, y representan un buen método de exploración si el interés es tener una mejor idea acerca de las características más influyentes en el set de datos.\n",
        "\n",
        "## **¿Cómo funciona?**\n",
        "\n",
        "Los árboles de decisión aprenden una serie reglas _if-else_ para los valores de las características/variables/atributos, este flujo de decisión (if-else) resulta en la predicción de una variable _target_.\n",
        "\n",
        "![img](https://drive.google.com/uc?id=1sFF_qHMLX9c4vS9iyQdx4naqTRHR-RLS)\n",
        "\n",
        "## **Ejemplo**\n",
        "\n",
        "Juego del si/no\n",
        "\n",
        "![img](https://drive.google.com/uc?id=1d1tZTed1jYySJsjxVU4ycLP1yYMSGQa1)\n",
        "\n",
        "Este ejemplo consiste en un simple juego de preguntas cuyas respuestas deben ser si o no. Una persona x deberá adivinar un objeto (variable target) que la otra persona esté imaginando, realizando una serie de preguntas, cuyo objetivo es ir reduciendo las posibilidades hasta llegar a la respuesta correcta.\n",
        "\n",
        "El flujo del ejemplo sería entonces:\n",
        "\n",
        "1. ¿Está vivo?  \n",
        "R. No\n",
        "\n",
        "2. ¿Vuela?  \n",
        "R. No\n",
        "\n",
        "3. ¿Puede llevar a más de 10 personas?  \n",
        "R. No\n",
        "\n",
        "4. Es un automóvil!\n",
        "\n",
        "Si lo notas, este flujo entonces tomará la forma de un **_árbol_** invertido y de ahí sus conceptos relacionados como:\n",
        "\n",
        "_Arbol de decisión_\n",
        "- Nodo raíz: nodo base del árbol\n",
        "- Nodo hoja: representan las clases del dataset y son la parte más externa del árbol (no tienen nodos \"hijos\").\n",
        "\n",
        "Con esto, es posible entonces diseñar una serie de reglas que resulten en un algoritmo capaz de aprender y pueda categorizar un objecto/variable.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "Ahora que tenemos una idea más clara sobre los árboles de decisión, podemos proceder a hablar sobre random forest.\n",
        "\n",
        "\n",
        "# **Random Forest**\n",
        "\n",
        "## **Introducción**\n",
        "\n",
        "Random Forest es uno de los métodos de Machine Learning más utilizados en el área y consiste en crear modelos de aprendizaje conocidos como _ensambles_ (unión). Un _ensamble_ (ensemble) consiste en agrupar múltiples modelos de aprendizaje y combinarlos, lo que produce un _modelo agregado_ que es mucho más \"poderoso\" (preciso) que los modelos individuales.\n",
        "\n",
        "**¿Por qué los ensambles son efectivos?**\n",
        "\n",
        "Aunque tengamos diferentes modelos de aprendizaje que individualmente se desempeñen \"bien\" (tengan una precisión aceptable), de igual forma tenderán a cometer diferentes tipos errores en un set de datos. Esto ocurre típicamente porque cada modelo podría [_sobreajustarse_](https://es.wikipedia.org/wiki/Sobreajuste) a diferentes porciones del set de datos. Al combinar diferentes modelos individuales en un ensamblaje podemos promediar sus errores para así reducir el riesgo de _sobreajuste_ y pueda _generalizar_ con mayor eficacia.\n",
        "\n",
        "Esta idea de ensamblaje es aplicada entonces al modelo Random Forest y dentro de éste podemos destacar:\n",
        "\n",
        "- Es un ensamblaje (agrupación) de muchos árboles de decisión.\n",
        "- Extensamente usado, debido a sus buenos resultados en diversos tipo de problemas.\n",
        "- módulo de scikit-learn -> [sklearn.ensemble](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble):\n",
        "  - Clasificación: RandomForestClassifier\n",
        "  - Regresión: RandomForestRegressor\n",
        "- Un árbol de decisión -> riesgo de sobreajuste.\n",
        "- Muchos árboles de decisión -> Más estable, generaliza mejor.\n",
        "- El ensamblaje de árboles debiera ser diverso: introducir una **variación al azar** en la construcción de árboles.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDYk1fOOyTy2"
      },
      "source": [
        "## **Proceso**\n",
        "\n",
        "![img](https://drive.google.com/uc?id=1ZdnIJoE9h2bEAQkEZcvi2dYu90ujBZ6Y)\n",
        "\n",
        "<br>\n",
        "\n",
        "**A nivel general los pasos que realiza el algoritmo son:**\n",
        "\n",
        "1. Se divide el set de datos al azar para construir cada árbol de decisión (_Bootstrap Samples_ / _Instances_)\n",
        "2. Se seleccionan las características al azar (_max_features_)\n",
        "3. Se define la cantidad de árboles a construir (n_estimator)\n",
        "4. Realiza una \"votación\" para cada resultado previsto.\n",
        "5. Selecciona el resultado de la predicción con más votos como la predicción final.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KBnor9n2F5E"
      },
      "source": [
        "## **A tener presente**\n",
        "\n",
        "- El algoritmo es altamente sensitivo al parámetro _max_features_\n",
        "- Cuando el parámetro _max_features_ equivale a 1, el algoritmo creará bosques más diversos y complejos.\n",
        "- Si el parámetro _max_features_ se acerca al número de características, los bosques serán más similares y simples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exvhsXkNAUXD"
      },
      "source": [
        "## **Desventajas**\n",
        "\n",
        "- Los bosques aleatorios son lentos en la generación de predicciones porque tiene múltiples árboles de decisión. Cada vez que hace una predicción, todos los árboles en el bosque tienen que hacer una predicción y luego votar sobre él. Todo este proceso lleva mucho tiempo.\n",
        "- El modelo es difícil de interpretar en comparación con un árbol de decisión, donde puede tomar una decisión fácilmente siguiendo la ruta en el árbol."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trY8sa63EKDV",
        "outputId": "ad30dd6f-a5df-45d4-a02d-c9c9bc326e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#Import de librerías\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "#Carga dataset\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFLvYpGaZbE7",
        "outputId": "dd5619ac-d9dd-4d21-c519-33f78e4fa2d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(iris.DESCR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            "        - sepal length in cm\n",
            "        - sepal width in cm\n",
            "        - petal length in cm\n",
            "        - petal width in cm\n",
            "        - class:\n",
            "                - Iris-Setosa\n",
            "                - Iris-Versicolour\n",
            "                - Iris-Virginica\n",
            "                \n",
            "    :Summary Statistics:\n",
            "\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "                    Min  Max   Mean    SD   Class Correlation\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
            "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
            "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
            "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
            "    ============== ==== ==== ======= ===== ====================\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "    :Class Distribution: 33.3% for each of 3 classes.\n",
            "    :Creator: R.A. Fisher\n",
            "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
            "    :Date: July, 1988\n",
            "\n",
            "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
            "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
            "Machine Learning Repository, which has two wrong data points.\n",
            "\n",
            "This is perhaps the best known database to be found in the\n",
            "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
            "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
            "data set contains 3 classes of 50 instances each, where each class refers to a\n",
            "type of iris plant.  One class is linearly separable from the other 2; the\n",
            "latter are NOT linearly separable from each other.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
            "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
            "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
            "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
            "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
            "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
            "     Structure and Classification Rule for Recognition in Partially Exposed\n",
            "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
            "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
            "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
            "     on Information Theory, May 1972, 431-433.\n",
            "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
            "     conceptual clustering system finds 3 classes in the data.\n",
            "   - Many, many more ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TC9YdSQaFKu"
      },
      "source": [
        "### **Planta [Iris](https://es.wikipedia.org/wiki/Iris_(planta)**\n",
        "\n",
        "#### _Especies_\n",
        "\n",
        "![img](https://drive.google.com/uc?id=1Ot5RSlSQCE5cEpSLXLcyXUq0suyzeYzk)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aJS__jhEKx8",
        "outputId": "47719c72-2585-4999-8219-4acc3580e624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# imprime las etiquetas de las especies(setosa, versicolor,virginica)\n",
        "print(iris.target_names)\n",
        "\n",
        "# imprime las características del dataset\n",
        "print(iris.feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['setosa' 'versicolor' 'virginica']\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS-EiW7BEOiT",
        "outputId": "1aa98a6b-a9ab-41d7-adbc-f38c39247c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "# imprime 5 1eros registros de los datos del dataset\n",
        "print(iris.data[0:5])\n",
        "\n",
        "# imprime las etiquetas del dataset (0:setosa, 1:versicolor, 2:virginica)\n",
        "print(iris.target)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i3o4ZvuER6_",
        "outputId": "854816a8-8840-4301-d18c-f6eef7488ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "# crea dataframe\n",
        "\n",
        "data=pd.DataFrame({\n",
        "    'sepal length':iris.data[:,0],\n",
        "    'sepal width':iris.data[:,1],\n",
        "    'petal length':iris.data[:,2],\n",
        "    'petal width':iris.data[:,3],\n",
        "    'species':iris.target\n",
        "})\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length</th>\n",
              "      <th>sepal width</th>\n",
              "      <th>petal length</th>\n",
              "      <th>petal width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length  sepal width  petal length  petal width  species\n",
              "0           5.1          3.5           1.4          0.2        0\n",
              "1           4.9          3.0           1.4          0.2        0\n",
              "2           4.7          3.2           1.3          0.2        0\n",
              "3           4.6          3.1           1.5          0.2        0\n",
              "4           5.0          3.6           1.4          0.2        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKFJekyYET1_"
      },
      "source": [
        "X = data[['sepal length', 'sepal width', 'petal length', 'petal width']]  # Características\n",
        "y = data['species']  # Etiquetas\n",
        "\n",
        "# crea subconjuntos de datos (traning set y test set)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBF5z_BEEWf3"
      },
      "source": [
        "# crea modelo de tipo Random Forest (clasificador)\n",
        "clf=RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Entrena el modelo con set de datos de entrenamiento\n",
        "clf.fit(X_train,y_train)\n",
        "\n",
        "# crea predicciones con datos de testing\n",
        "y_pred=clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc-VykaCEX7n",
        "outputId": "c1501f01-f103-4b80-bc94-0ebff536eec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# mide precisión del modelo\n",
        "print(\"Precisión: \", metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precisión:  0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t97txBgAa4lt",
        "outputId": "7f457b66-5328-42aa-f051-8754b7e45040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = pd.DataFrame({'Real': y_test, 'Predecido': clf.predict(X_test).flatten()})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Real</th>\n",
              "      <th>Predecido</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Real  Predecido\n",
              "27      0          0\n",
              "138     2          2\n",
              "108     2          2\n",
              "60      1          1\n",
              "136     2          2\n",
              "140     2          2\n",
              "132     2          2\n",
              "33      0          0\n",
              "129     2          2\n",
              "95      1          1\n",
              "112     2          2\n",
              "106     2          1\n",
              "133     2          1\n",
              "104     2          2\n",
              "91      1          1\n",
              "80      1          1\n",
              "77      1          2\n",
              "65      1          1\n",
              "53      1          1\n",
              "38      0          0\n",
              "1       0          0\n",
              "56      1          1\n",
              "72      1          1\n",
              "14      0          0\n",
              "116     2          2\n",
              "49      0          0\n",
              "41      0          0\n",
              "144     2          2\n",
              "102     2          2\n",
              "118     2          2\n",
              "24      0          0\n",
              "86      1          1\n",
              "121     2          2\n",
              "51      1          1\n",
              "68      1          1\n",
              "47      0          0\n",
              "141     2          2\n",
              "75      1          1\n",
              "82      1          1\n",
              "25      0          0\n",
              "2       0          0\n",
              "69      1          1\n",
              "43      0          0\n",
              "85      1          1\n",
              "148     2          2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L9dtXqsEcHf",
        "outputId": "f1b49cac-1ca5-46ba-dc9a-6a94155e3ee6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "# mide la \"importancia/influencia\" de cada una de las características \n",
        "feature_imp = pd.Series(clf.feature_importances_, index=iris.feature_names).sort_values(ascending=False)\n",
        "feature_imp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "petal width (cm)     0.448239\n",
              "petal length (cm)    0.426404\n",
              "sepal length (cm)    0.096513\n",
              "sepal width (cm)     0.028844\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytF-4u1KFzTo",
        "outputId": "8a4dace0-18fb-474e-abab-789dcff884d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "%matplotlib inline\n",
        "# Crea gráfico de barras\n",
        "sns.barplot(x=feature_imp, y=feature_imp.index)\n",
        "# Añade etiquetas\n",
        "plt.xlabel('Puntaje de importancia de la característica')\n",
        "plt.ylabel('Características')\n",
        "plt.title(\"Visualizando la importancia de las características\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}